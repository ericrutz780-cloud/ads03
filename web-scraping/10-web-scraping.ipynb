{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E: Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Manually scraping sz.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://sz.de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html lang=\"de\">\n",
      "\n",
      "<head>\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <title>Aktuelle Nachrichten, Hintergr端nde und Kommentare - SZ.de</title>\n",
      "    <link rel=\"canonical\" href=\"https://www.sueddeutsche.de\" />\n",
      "    <meta name=\"robots\" content=\"index,follow,noarchive,noodp\" />\n",
      "    <meta name=\"author\" content=\"S端ddeutsche.de GmbH, Munich, Germany\" />\n",
      "    <meta name=\"copyright\" content=\"S端ddeutsche.de GmbH, Munich, Germany\" />\n",
      "    <meta name=\"viewport\" content=\"width=1280\" />\n",
      "    <meta name=\"email\" content=\"kontakt@sueddeutsche.de\" />\n",
      "    <meta name=\"description\" content=\"News aus Deutschland und aller Welt mit Kommentaren und Hintergrundberichten auf S端ddeutsche.de.\" />\n",
      "    <meta name=\"keyword [...]\n"
     ]
    }
   ],
   "source": [
    "print(response.text[0:700], \"[...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html>\\n<html lang=\"de\">\\n\\n<head>\\n    <meta charset=\"utf-8\" />\\n    <title>Aktuelle Nachrichten, Hintergr\\xc3\\xbcnde und Kommentare - SZ.de</title>\\n    <link rel=\"canonical\" href=\"https://www.sueddeutsche.de\" />\\n    <meta name=\"robots\" content=\"index,follow,noarchive,noodp\" />\\n    <meta name=\"author\" content=\"S\\xc3\\xbcddeutsche.de GmbH, Munich, Germany\" />\\n    <meta name=\"copyright\" content=\"S\\xc3\\xbcddeutsche.de GmbH, Munich, Germany\" />\\n    <meta name=\"viewport\" content=\"width=1280\" />\\n    <meta name=\"email\" content=\"kontakt@sueddeutsche.de\" />\\n    <meta name=\"description\" content=\"News aus Deutschland und aller Welt mit Kommentaren und Hintergrundberichten auf S\\xc3\\xbcddeutsche.de.\" />\\n    <meta name=\"key' [...]\n"
     ]
    }
   ],
   "source": [
    "print(response.content[0:700], \"[...]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sueddeutsche.de/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(microseconds=75485)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'local/sz.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msz.html\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(response\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'local/sz.html'"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(\"local\", \"sz.html\"), \"wb\") as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: automatically scraping multiple websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE_DIR = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of news pages to be scraped\n",
    "newspaper_urls = dict(\n",
    "    sz=\"https://www.sueddeutsche.de/\",\n",
    "    zeit=\"https://www.zeit.de/index\",\n",
    "    faz=\"https://www.faz.net/aktuell/\",\n",
    "    ts=\"https://www.tagesspiegel.de/\",\n",
    "    spiegel=\"https://www.spiegel.de/\",\n",
    "    kronen=\"https://www.krone.at/\",\n",
    "    wtf=\"https://asdfkajwlkejwkejklajsdflksadjfasdf.nix\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-22\n"
     ]
    }
   ],
   "source": [
    "# Current date as string\n",
    "now = datetime.now()\n",
    "now_str = now.strftime(\"%Y-%m-%d\")\n",
    "print(now_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target objects\n",
    "\n",
    "We will create two objects:\n",
    "\n",
    "- `content_dict`: a dict with the HTML content of the pages we scraped\n",
    "- `log_list`: a list with metadata about our requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_dict = {}\n",
    "text_dict = {}\n",
    "log_list = []\n",
    "failing_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_website(name, url):\n",
    "    # (1) Run request\n",
    "    response = requests.get(url, allow_redirects=True)\n",
    "    content = response.content\n",
    "    text = response.text\n",
    "\n",
    "    # (2) File name to store the raw HTML\n",
    "    file_name = os.path.join(\n",
    "        STORAGE_DIR,\n",
    "        f\"{now_str}-{name}.html\",\n",
    "    )\n",
    "\n",
    "    # (3) Write raw HTML\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    # (4) Fill content_dict and text_dict\n",
    "    content_dict[name] = response.content\n",
    "    text_dict[name] = response.text\n",
    "\n",
    "    # (5) Fill log_list\n",
    "    log_info = dict(\n",
    "        name=name,\n",
    "        date=now_str,\n",
    "        file_name=file_name,\n",
    "        status=response.status_code,\n",
    "        url=response.url,\n",
    "        encoding=response.encoding,\n",
    "    )\n",
    "    log_list.append(log_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, url in newspaper_urls.items():\n",
    "    try:\n",
    "        scrape_website(name, url)\n",
    "    except:\n",
    "        failing_list.append((name, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df = pd.DataFrame(log_list)\n",
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = os.path.join(\n",
    "    STORAGE_DIR,\n",
    "    f\"{now_str}.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.to_csv(log_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wtf', 'https://asdfkajwlkejwkejklajsdflksadjfasdf.nix')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
